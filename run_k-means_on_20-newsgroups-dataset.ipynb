{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of K-means on [20 Newsgroups data set](http://qwone.com/~jason/20Newsgroups/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import collections\n",
    "import datetime as dt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import K_Means_Algorithm as km\n",
    "from sklearn.cluster import KMeans #for comparison\n",
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data, test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abomin', 'abort', 'abound', 'abraham', 'abridg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = pd.read_csv(\".//data//News_groups_terms.txt\", sep='\\t', header=None) \n",
    "terms_lst = list(terms[0])\n",
    "terms_lst[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aargh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronc</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abid</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>...</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>zrb</th>\n",
       "      <th>zs</th>\n",
       "      <th>zu</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 9328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aargh  aaron  aaronc  ab  abandon  abc  abid  abil  abl  ...  zq  zr  \\\n",
       "0   0      0      0       0   0        0    0     0     0    0  ...   0   0   \n",
       "1   0      0      0       0   0        0    0     0     0    1  ...   0   0   \n",
       "2   0      0      0       0   0        0    0     0     0    0  ...   0   0   \n",
       "3   0      0      0       0   0        0    0     0     0    0  ...   0   0   \n",
       "4   0      0      0       0   0        0    0     0     0    0  ...   0   0   \n",
       "\n",
       "   zrb  zs  zu  zubov  zv  zw  zx  zz  \n",
       "0    0   0   0      0   0   0   0   0  \n",
       "1    0   0   0      0   0   0   0   0  \n",
       "2    0   0   0      0   0   0   0   0  \n",
       "3    0   0   0      0   0   0   0   0  \n",
       "4    0   0   0      0   0   0   0   0  \n",
       "\n",
       "[5 rows x 9328 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the term (rows) X document (columns) matrix:\n",
    "term_doc_matrix = pd.read_csv(\".//data//News_groups_matrix.txt\", sep=',', header = None) \n",
    "doc_term_matrix = term_doc_matrix.T\n",
    "doc_term_matrix.columns = terms_lst\n",
    "doc_term_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aargh</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronc</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abc</th>\n",
       "      <th>abid</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>...</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>zrb</th>\n",
       "      <th>zs</th>\n",
       "      <th>zu</th>\n",
       "      <th>zubov</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "      <td>2.50e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.40e-03</td>\n",
       "      <td>2.40e-03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4.80e-03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.00e-03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.60e-03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>...</td>\n",
       "      <td>5.20e-03</td>\n",
       "      <td>6.40e-03</td>\n",
       "      <td>1.60e-03</td>\n",
       "      <td>7.60e-03</td>\n",
       "      <td>2.80e-03</td>\n",
       "      <td>3.20e-03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>4.40e-03</td>\n",
       "      <td>2.40e-03</td>\n",
       "      <td>6.00e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.38e-01</td>\n",
       "      <td>4.89e-02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>8.47e-02</td>\n",
       "      <td>0.23</td>\n",
       "      <td>6.92e-02</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4.90e-02</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>1.04e-01</td>\n",
       "      <td>1.88e-01</td>\n",
       "      <td>4.90e-02</td>\n",
       "      <td>1.95e-01</td>\n",
       "      <td>8.72e-02</td>\n",
       "      <td>6.92e-02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.66e-01</td>\n",
       "      <td>8.48e-02</td>\n",
       "      <td>1.56e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "      <td>0.00e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.00e+00</td>\n",
       "      <td>1.00e+00</td>\n",
       "      <td>47.00</td>\n",
       "      <td>2.00e+00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2.00e+00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2.00e+00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00e+00</td>\n",
       "      <td>7.00e+00</td>\n",
       "      <td>2.00e+00</td>\n",
       "      <td>8.00e+00</td>\n",
       "      <td>3.00e+00</td>\n",
       "      <td>2.00e+00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>8.00e+00</td>\n",
       "      <td>4.00e+00</td>\n",
       "      <td>5.00e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 9328 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa     aargh    aaron    aaronc       ab   abandon      abc  \\\n",
       "count  2.50e+03  2.50e+03  2500.00  2.50e+03  2500.00  2.50e+03  2500.00   \n",
       "mean   6.40e-03  2.40e-03     0.03  4.80e-03     0.01  4.00e-03     0.02   \n",
       "std    1.38e-01  4.89e-02     0.95  8.47e-02     0.23  6.92e-02     0.25   \n",
       "min    0.00e+00  0.00e+00     0.00  0.00e+00     0.00  0.00e+00     0.00   \n",
       "25%    0.00e+00  0.00e+00     0.00  0.00e+00     0.00  0.00e+00     0.00   \n",
       "50%    0.00e+00  0.00e+00     0.00  0.00e+00     0.00  0.00e+00     0.00   \n",
       "75%    0.00e+00  0.00e+00     0.00  0.00e+00     0.00  0.00e+00     0.00   \n",
       "max    6.00e+00  1.00e+00    47.00  2.00e+00     9.00  2.00e+00     7.00   \n",
       "\n",
       "           abid     abil      abl  ...        zq        zr       zrb  \\\n",
       "count  2.50e+03  2500.00  2500.00  ...  2.50e+03  2.50e+03  2.50e+03   \n",
       "mean   1.60e-03     0.03     0.08  ...  5.20e-03  6.40e-03  1.60e-03   \n",
       "std    4.90e-02     0.24     0.35  ...  1.04e-01  1.88e-01  4.90e-02   \n",
       "min    0.00e+00     0.00     0.00  ...  0.00e+00  0.00e+00  0.00e+00   \n",
       "25%    0.00e+00     0.00     0.00  ...  0.00e+00  0.00e+00  0.00e+00   \n",
       "50%    0.00e+00     0.00     0.00  ...  0.00e+00  0.00e+00  0.00e+00   \n",
       "75%    0.00e+00     0.00     0.00  ...  0.00e+00  0.00e+00  0.00e+00   \n",
       "max    2.00e+00     6.00     4.00  ...  3.00e+00  7.00e+00  2.00e+00   \n",
       "\n",
       "             zs        zu     zubov       zv        zw        zx        zz  \n",
       "count  2.50e+03  2.50e+03  2.50e+03  2500.00  2.50e+03  2.50e+03  2.50e+03  \n",
       "mean   7.60e-03  2.80e-03  3.20e-03     0.02  4.40e-03  2.40e-03  6.00e-03  \n",
       "std    1.95e-01  8.72e-02  6.92e-02     0.52  1.66e-01  8.48e-02  1.56e-01  \n",
       "min    0.00e+00  0.00e+00  0.00e+00     0.00  0.00e+00  0.00e+00  0.00e+00  \n",
       "25%    0.00e+00  0.00e+00  0.00e+00     0.00  0.00e+00  0.00e+00  0.00e+00  \n",
       "50%    0.00e+00  0.00e+00  0.00e+00     0.00  0.00e+00  0.00e+00  0.00e+00  \n",
       "75%    0.00e+00  0.00e+00  0.00e+00     0.00  0.00e+00  0.00e+00  0.00e+00  \n",
       "max    8.00e+00  3.00e+00  2.00e+00    20.00  8.00e+00  4.00e+00  5.00e+00  \n",
       "\n",
       "[8 rows x 9328 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most terms show up sparsely across the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw a heatmap with the numeric values in each cell\n",
    "# f, ax = plt.subplots(figsize=(15, 20))\n",
    "# sns.heatmap(doc_term_matrix.head(50), annot=False, fmt=\"d\", linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the dataset is too large and sparse to visualize with a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1\n",
       "0   \n",
       "0  0\n",
       "1  1\n",
       "2  1\n",
       "3  1\n",
       "4  2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = pd.read_csv(\".//data//News_groups_classes.txt\", sep=' ', header=None, skiprows=1, index_col=0) \n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 9328)\n",
      "(2500, 1)\n",
      "(9328, 1)\n"
     ]
    }
   ],
   "source": [
    "print(doc_term_matrix.shape)\n",
    "print(classes.shape)\n",
    "print(terms.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_train, doc_term_matrix_test, classes_train, classes_test = train_test_split(doc_term_matrix, \n",
    "                                                                               classes, test_size=0.2, \n",
    "                                                                               random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 9328), (500, 9328))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_term_matrix_train.shape, doc_term_matrix_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn raw term frequencies into TFxIDF values \n",
    "(be sure to maintain DF values for each of the terms in the dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = doc_term_matrix_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7]\n",
      " [ 4]\n",
      " [17]\n",
      " ...\n",
      " [ 2]\n",
      " [ 1]\n",
      " [ 2]]\n"
     ]
    }
   ],
   "source": [
    "# Find document frequencies for each term\n",
    "docFreq = np.array([(TD!=0).sum(1)]).T #counts nonzero entries for each term \n",
    "print(docFreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(docFreq == 0)[0])\n",
    "# => there are 15 terms that don't appear in any documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NDocs = doc_term_matrix_train.shape[0]\n",
    "NDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2000. 2000. 2000. ... 2000. 2000. 2000.]\n",
      " [2000. 2000. 2000. ... 2000. 2000. 2000.]\n",
      " [2000. 2000. 2000. ... 2000. 2000. 2000.]\n",
      " ...\n",
      " [2000. 2000. 2000. ... 2000. 2000. 2000.]\n",
      " [2000. 2000. 2000. ... 2000. 2000. 2000.]\n",
      " [2000. 2000. 2000. ... 2000. 2000. 2000.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix with all entries = NDocs\n",
    "NMatrix=np.ones(np.shape(TD), dtype=float)*NDocs\n",
    "np.set_printoptions(precision=2,suppress=True,linewidth=120)\n",
    "print (NMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\renel.chesak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.16  8.16  8.16 ...  8.16  8.16  8.16]\n",
      " [ 8.97  8.97  8.97 ...  8.97  8.97  8.97]\n",
      " [ 6.88  6.88  6.88 ...  6.88  6.88  6.88]\n",
      " ...\n",
      " [ 9.97  9.97  9.97 ...  9.97  9.97  9.97]\n",
      " [10.97 10.97 10.97 ... 10.97 10.97 10.97]\n",
      " [ 9.97  9.97  9.97 ...  9.97  9.97  9.97]]\n"
     ]
    }
   ],
   "source": [
    "# Convert each entry into IDF values\n",
    "# Note that IDF is only a function of the term, so all columns will be identical.\n",
    "IDF = np.log2(np.divide(NMatrix, docFreq)) \n",
    "print(IDF) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above that there is a warning saying that it is encountering an issue where it has to divide by zero. This is actually creating INF (infinite) values where ever this happens. We encounter dividing by zero when the DF (NK) is zero (meaning the term doesn't appear in any documents). We need to replace these 'inf' values with some float to move on to the next step in our computation.\n",
    "\n",
    "IDF provides high values for rare words and low values for common words, so infinite is appropriate, it just can't be used in computations. Two good options would be either making them really, really, big numbers, or removing them from the DT matrix altogether. We will proceed with the former."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define inf:\n",
    "positive_inf = float('+inf')\n",
    "\n",
    "#set all inf values to a large number:\n",
    "IDF[IDF == positive_inf] = 100000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1289</th>\n",
       "      <th>596</th>\n",
       "      <th>1935</th>\n",
       "      <th>2436</th>\n",
       "      <th>2349</th>\n",
       "      <th>40</th>\n",
       "      <th>1018</th>\n",
       "      <th>502</th>\n",
       "      <th>1534</th>\n",
       "      <th>1445</th>\n",
       "      <th>...</th>\n",
       "      <th>2044</th>\n",
       "      <th>1422</th>\n",
       "      <th>1747</th>\n",
       "      <th>2109</th>\n",
       "      <th>102</th>\n",
       "      <th>2243</th>\n",
       "      <th>57</th>\n",
       "      <th>578</th>\n",
       "      <th>1752</th>\n",
       "      <th>2439</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aargh</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaronc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zubov</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zw</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zx</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9328 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1289  596   1935  2436  2349  40    1018  502   1534  1445  ...  2044  \\\n",
       "aa       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "aargh    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "aaron    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "aaronc   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "ab       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "zubov    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zv       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zw       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zx       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "zz       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "        1422  1747  2109  102   2243  57    578   1752  2439  \n",
       "aa       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "aargh    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "aaron    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "aaronc   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "ab       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "zubov    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "zv       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "zw       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "zx       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "zz       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[9328 rows x 2000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally compute the TFxIDF values for each document-term entry\n",
    "#TD_tfidf = TD * IDF\n",
    "TD_tfidf = np.multiply(TD, IDF)\n",
    "TD_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that most values are zero; this is a sparse matrix as noted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9328)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_tfidf = TD_tfidf.T\n",
    "DT_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9328)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows (terms) where NULLs exist:\n",
    "DT_tfidf_not_null = DT_tfidf[~np.isnan(DT_tfidf).any(axis=1)]\n",
    "DT_tfidf_not_null.shape #NO NULLS EXIST! :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create term-freqency dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9328"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numTerms = doc_term_matrix_train.shape[1]\n",
    "numTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aa', array([7], dtype=int64)), ('aargh', array([4], dtype=int64)), ('aaron', array([17], dtype=int64)), ('aaronc', array([6], dtype=int64)), ('ab', array([9], dtype=int64))]\n"
     ]
    }
   ],
   "source": [
    "dictTF = {terms_lst[i]:docFreq[i] for i in range(numTerms)}             \n",
    "print(list(islice(dictTF.items(), 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform K-Means clustering on the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the matrix into a 2D numpy array\n",
    "DT_tfidf = np.array(DT_tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time to compute: 0:00:47.972943\n"
     ]
    }
   ],
   "source": [
    "#run k-means\n",
    "start = dt.datetime.now()\n",
    "centroids, cluster = km.Train.KMeansClustering(DT_tfidf, k=5)\n",
    "end = dt.datetime.now()\n",
    "print('\\nTime to compute: {}'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs in clusters:\n",
      "Cluster 2 : 786\n",
      "Cluster 4 : 408\n",
      "Cluster 0 : 405\n",
      "Cluster 3 : 393\n",
      "Cluster 1 : 8\n"
     ]
    }
   ],
   "source": [
    "cluster_counts_dict = collections.Counter(cluster[:, 0])\n",
    "print(\"Number of docs in clusters:\")\n",
    "for key in cluster_counts_dict:\n",
    "    print(\"Cluster\", int(key), ':',  cluster_counts_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create arrays\n",
    "doc_term_matrix_train_arr = np.array(doc_term_matrix_train)\n",
    "terms_arr = np.array(terms_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you guess which cluster is which based on the following categories?\n",
    "- windows \n",
    "- crypt\n",
    "- christian\n",
    "- hockey\n",
    "- forsale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###############################################\n",
      "Cluster: 0\n",
      "\t-----------------------\n",
      "\tNumber of docs in cluster: 405\n",
      "\t-----------------------\n",
      "\t-----------------------\n",
      "\tTop N terms | % of docs in cluster that contain those terms\n",
      "\t-----------------------\n",
      "\t        kei | 45.9%\n",
      "\t    encrypt | 45.7%\n",
      "\t       chip | 38.8%\n",
      "\t      secur | 28.9%\n",
      "\t     govern | 33.6%\n",
      "\t    clipper | 45.7%\n",
      "\t    privaci | 12.3%\n",
      "\t     anonym | 4.7%\n",
      "\t  algorithm | 24.7%\n",
      "\t     system | 30.6%\n",
      "###############################################\n",
      "\n",
      "###############################################\n",
      "Cluster: 1\n",
      "\t-----------------------\n",
      "\tNumber of docs in cluster: 8\n",
      "\t-----------------------\n",
      "\t-----------------------\n",
      "\tTop N terms | % of docs in cluster that contain those terms\n",
      "\t-----------------------\n",
      "\t         ax | 87.5%\n",
      "\t        max | 87.5%\n",
      "\t         pl | 75.0%\n",
      "\t        giz | 75.0%\n",
      "\t        bxn | 75.0%\n",
      "\t         wm | 75.0%\n",
      "\t         qq | 75.0%\n",
      "\t         mq | 75.0%\n",
      "\t        asq | 75.0%\n",
      "\t        nui | 75.0%\n",
      "###############################################\n",
      "\n",
      "###############################################\n",
      "Cluster: 2\n",
      "\t-----------------------\n",
      "\tNumber of docs in cluster: 786\n",
      "\t-----------------------\n",
      "\t-----------------------\n",
      "\tTop N terms | % of docs in cluster that contain those terms\n",
      "\t-----------------------\n",
      "\t     window | 37.5%\n",
      "\t       file | 19.3%\n",
      "\t         do | 20.0%\n",
      "\t       sale | 28.8%\n",
      "\t     driver | 10.3%\n",
      "\t       card | 15.4%\n",
      "\t       mous | 5.2%\n",
      "\t    program | 16.9%\n",
      "\t      drive | 12.6%\n",
      "\t        run | 18.6%\n",
      "###############################################\n",
      "\n",
      "###############################################\n",
      "Cluster: 3\n",
      "\t-----------------------\n",
      "\tNumber of docs in cluster: 393\n",
      "\t-----------------------\n",
      "\t-----------------------\n",
      "\tTop N terms | % of docs in cluster that contain those terms\n",
      "\t-----------------------\n",
      "\t         db | 0.5%\n",
      "\t        god | 54.2%\n",
      "\t  christian | 45.8%\n",
      "\t     church | 27.0%\n",
      "\t       jesu | 26.2%\n",
      "\t   homosexu | 9.7%\n",
      "\t        sin | 20.1%\n",
      "\t         bh | 0.5%\n",
      "\t     christ | 27.2%\n",
      "\t       paul | 18.1%\n",
      "###############################################\n",
      "\n",
      "###############################################\n",
      "Cluster: 4\n",
      "\t-----------------------\n",
      "\tNumber of docs in cluster: 408\n",
      "\t-----------------------\n",
      "\t-----------------------\n",
      "\tTop N terms | % of docs in cluster that contain those terms\n",
      "\t-----------------------\n",
      "\t         cx | 1.2%\n",
      "\t       game | 52.5%\n",
      "\t       team | 47.5%\n",
      "\t       plai | 40.4%\n",
      "\t         uw | 1.5%\n",
      "\t     player | 29.9%\n",
      "\t         gm | 4.9%\n",
      "\t     hockei | 39.0%\n",
      "\t     season | 23.8%\n",
      "\t       goal | 20.3%\n",
      "###############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print results\n",
    "km.Train.printDocClusterSummary(centroids, cluster, 10, doc_term_matrix_train_arr, terms_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using KMeans() from sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5, max_iter=500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=500,\n",
       "       n_clusters=5, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(DT_tfidf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cluster assignments\n",
    "clusters_sklearn = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs in clusters:\n",
      "Cluster 0 : 1994\n",
      "Cluster 2 : 2\n",
      "Cluster 3 : 1\n",
      "Cluster 4 : 1\n",
      "Cluster 1 : 2\n"
     ]
    }
   ],
   "source": [
    "cluster_counts_dict = collections.Counter(clusters_sklearn)\n",
    "print(\"Number of docs in clusters:\")\n",
    "for key in cluster_counts_dict:\n",
    "    print(\"Cluster\", int(key), ':',  cluster_counts_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are not at all similar to what the hand-built `KMeansClustering` function got. `sklearn`'s `KMeans` doesn't appear to work so well on this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute the Completeness and Homogeneity values of the cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the classes a 1D array so it can be compared with the cluster assignments\n",
    "classes_train_arr = np.array(classes_train)\n",
    "classes_train_arr = classes_train_arr.reshape(1, -1)\n",
    "classes_train_arr = classes_train_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab the cluster assignments from the K_Means() output:\n",
    "cluster_assignments = cluster[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8491846979303588"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_score(classes_train_arr, cluster_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our clusters have a good completeness score, and it is similar to an 85% accuracy score (based upon the true class assignments). A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715828717504507"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneity_score(classes_train_arr, cluster_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters have a pretty good homogeneity score; there is about a 72% \"sameness\" in each cluster. This means the clusters have pretty decent inter-cluster similarity. Overall, we can conclude that our algorithm did just about as well as whatever algorithm clustered them to create those 'true' classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the quality of the clustering with Silhouete vales\n",
    "One way to measure the quality of clustering is to compute the Silhouette values for each instance in the data. The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation). It is the ratio of the difference between in-cluster dissimilarity and the closest out-of-cluster dissimilarity, and the maximum of these two values. The silhouette ranges from âˆ’1 to +1, where a high value indicates that the object is well matched to its own cluster and well separated from other clusters. If most objects have a high value, then the clustering configuration is appropriate. If many points have a low or negative value, then the clustering configuration may have too many or too few clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouettes = metrics.silhouette_samples(DT_tfidf, cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_silhouettes(data, clusters, metric='euclidean'):\n",
    "\n",
    "    cluster_labels = np.unique(clusters)\n",
    "    n_clusters = cluster_labels.shape[0]\n",
    "    silhouette_vals = metrics.silhouette_samples(data, clusters, metric='euclidean')\n",
    "    c_ax_lower, c_ax_upper = 0, 0\n",
    "    cticks = []\n",
    "    for i, k in enumerate(cluster_labels):\n",
    "        c_silhouette_vals = silhouette_vals[clusters == k]\n",
    "        c_silhouette_vals.sort()\n",
    "        c_ax_upper += len(c_silhouette_vals)\n",
    "        color = cm.jet(float(i) / n_clusters)\n",
    "        plt.barh(range(c_ax_lower, c_ax_upper), c_silhouette_vals, height=1.0, \n",
    "                      edgecolor='none', color=color)\n",
    "\n",
    "        cticks.append((c_ax_lower + c_ax_upper) / 2)\n",
    "        c_ax_lower += len(c_silhouette_vals)\n",
    "    \n",
    "    silhouette_avg = np.mean(silhouette_vals)\n",
    "    plt.axvline(silhouette_avg, color=\"red\", linestyle=\"--\") \n",
    "\n",
    "    plt.yticks(cticks, cluster_labels)\n",
    "    plt.ylabel('Cluster')\n",
    "    plt.xlabel('Silhouette coefficient')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig('images/11_04.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_silhouettes(DT_tfidf, cluster_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the silhouette plot that the clusters are not so different from eachother, and that is likely due to the sparsity of the matrix. Since most documents have zero occurences of most terms, the clusters appear to be a bit meaningless. Thus, due to the sparsity of the matrix, silhouette values don't provide much information and aren't so useful. It is more meaningful to see whether the clustering produced cluster assignments that match the ground-truth classes, which we saw in the completeness and homogeneity scores above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize each of the documents in the test set\n",
    "Here the hand-built `NearestNeighborClassifier()` is used to determine which cluster each document falls into. For this, the centroids generated from the hand-built `KMeansClustering()` function are used as the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9328)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create numpy array\n",
    "doc_term_matrix_test_array = np.array(doc_term_matrix_test)\n",
    "doc_term_matrix_test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results, predicted_cluster_assignments = km.Train.NearestNeighborClassifier(centroids, doc_term_matrix_test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the ground-truth classes a 1D array so it can be compared with the cluster assignments\n",
    "classes_test_arr = np.array(classes_test)\n",
    "classes_test_arr = classes_test_arr.reshape(1, -1)\n",
    "classes_test_arr = classes_test_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8250147931195887"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completeness_score(classes_test_arr, predicted_cluster_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our clusters have a good completeness score, and it is similar to the 83% completeness score we got on the training set. It is normal for the test set to perform slightly worse, as some overfitting is part of the variance-bias tradeoff. \n",
    "\n",
    "Note: A clustering result satisfies completeness if all the data points that are members of a given class are elements of the same cluster. It is similar to an accuracy score because it's based on predicted vs. actual classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6881070480516535"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homogeneity_score(classes_test_arr, predicted_cluster_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is also similar to what we got for the training set, so we are in good shape with our classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
